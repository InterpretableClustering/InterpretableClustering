{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 77886,
     "status": "ok",
     "timestamp": 1598983475587,
     "user_tz": 240
    },
    "id": "QCQkSqrFKn1N",
    "outputId": "3909d643-f7fd-49a6-fd58-b0e94e270b96",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install dgl-cu101\n",
    "#!pip install dynamicgem\n",
    "#!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4293,
     "status": "ok",
     "timestamp": 1598996368022,
     "user_tz": 240
    },
    "id": "d5QApBmLhOGP",
    "outputId": "53fe9fe5-7da2-4755-8250-c6554cb25cf7"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils import encode_onehot\n",
    "from models import RGCN,GCNLSTM,GCN,dgl_GCN,GAT,GraphSage,EGCN,LSTMGCN,RNNGCN,TRNNGCN\n",
    "\n",
    "import tensorflow\n",
    "from dynamicgem.embedding.dynAERNN  import DynAERNN\n",
    "\n",
    "import dgl\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from scipy import stats  \n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import permutations \n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5CMAPT6gafH"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XQhTdRFI2VB"
   },
   "outputs": [],
   "source": [
    "def one_hot(l,classnum=1): #classnum fix some special case\n",
    "    one_hot_l=np.zeros((len(l),max(l.max()+1,classnum)))\n",
    "    for i in range(len(l)):\n",
    "        one_hot_l[i][l[i]]=1\n",
    "    return one_hot_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_w-ZeV-gYDI"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, features, adj, labels, idx_train, idx_val, model_type):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    #print(features.shape)\n",
    "    output = model(features, adj)\n",
    "    \n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    \n",
    "    pred_labels=torch.argmax(output,axis=1)\n",
    "    acc_train = metrics.accuracy_score(pred_labels[idx_train].cpu().detach().numpy(),labels[idx_train].cpu().detach().numpy())\n",
    "    \n",
    "\n",
    "    loss_train.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    #print(loss_train,acc_train)\n",
    "\n",
    "    #validation\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    \n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = metrics.accuracy_score(pred_labels[idx_val].cpu().detach().numpy(),labels[idx_val].cpu().detach().numpy())\n",
    "    #print(loss_val,acc_val)\n",
    "    '''\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    \n",
    "    a.write('Epoch: {:04d}'.format(epoch+1)+' '+\n",
    "          'loss_train: {:.4f}'.format(loss_train.item())+' '+\n",
    "          'acc_train: {:.4f}'.format(acc_train.item())+' '+\n",
    "          'loss_val: {:.4f}'.format(loss_val.item())+' '+\n",
    "          'acc_val: {:.4f}'.format(acc_val.item())+' '+\n",
    "          'time: {:.4f}s'.format(time.time() - t)+'\\n')\n",
    "    a.close()\n",
    "    '''\n",
    "    return acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRjSx8U6gSoo"
   },
   "outputs": [],
   "source": [
    "def test(model, features, adj, labels, idx_test):\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    pred_labels=torch.argmax(output,axis=1)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = metrics.accuracy_score(labels[idx_test].cpu().detach().numpy(), pred_labels[idx_test].cpu().detach().numpy())\n",
    "    f1_test=metrics.f1_score(labels[idx_test].cpu().detach().numpy(), pred_labels[idx_test].cpu().detach().numpy(),average='weighted')\n",
    "    auc_test=metrics.roc_auc_score(one_hot(labels[idx_test].cpu().detach().numpy()), output[idx_test].cpu().detach().numpy(),multi_class='ovr',average='weighted')\n",
    "    \n",
    "    return loss_test.item(), acc_test, f1_test, auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGI0UEsy7-Og"
   },
   "outputs": [],
   "source": [
    "def getNormLaplacian(W):\n",
    "\t\"\"\"input matrix W=(w_ij)\n",
    "\t\"compute D=diag(d1,...dn)\n",
    "\t\"and L=D-W\n",
    "\t\"and Lbar=D^(-1/2)LD^(-1/2)\n",
    "\t\"return Lbar\n",
    "\t\"\"\"\n",
    "\td=[np.sum(row) for row in W]\n",
    "\tD=np.diag(d)\n",
    "\tL=D-W\n",
    "\tDn=np.power(np.linalg.matrix_power(D,-1),0.5)\n",
    "\tLbar=np.dot(np.dot(Dn,L),Dn)\n",
    "\treturn Lbar\n",
    " \n",
    "def getKlargestEigVec(Lbar,k):\n",
    "\t\"\"\"input\n",
    "\t\"matrix Lbar and k\n",
    "\t\"return\n",
    "\t\"k largest eigen values and their corresponding eigen vectors\n",
    "\t\"\"\"\n",
    "\teigval,eigvec=linalg.eig(Lbar)\n",
    "\tdim=len(eigval)\n",
    " \n",
    "\t#find top k largest eigval\n",
    "\tdictEigval=dict(zip(eigval,range(0,dim)))\n",
    "\tkEig=np.sort(eigval)[::-1][:k]#[0:k]\n",
    "\tix=[dictEigval[k] for k in kEig]\n",
    "\treturn eigval[ix],eigvec[:,ix]\n",
    " \n",
    "def getKlargestSigVec(Lbar,k):\n",
    "\t\"\"\"input\n",
    "\t\"matrix Lbar and k\n",
    "\t\"return\n",
    "\t\"k largest singular values and their corresponding eigen vectors\n",
    "\t\"\"\"\n",
    "\tlsigvec,sigval,rsigvec=linalg.svd(Lbar)\n",
    "\tdim=len(sigval)\n",
    " \n",
    "\t#find top k largest left sigval\n",
    "\tdictSigval=dict(zip(sigval,range(0,dim)))\n",
    "\tkSig=np.sort(sigval)[::-1][:k]#[0:k]\n",
    "\tix=[dictSigval[k] for k in kSig]\n",
    "\treturn sigval[ix],lsigvec[:,ix]\n",
    "\n",
    "def checkResult(Lbar,eigvec,eigval,k):\n",
    "\t\"\"\"\n",
    "\t\"input\n",
    "\t\"matrix Lbar and k eig values and k eig vectors\n",
    "\t\"print norm(Lbar*eigvec[:,i]-lamda[i]*eigvec[:,i])\n",
    "\t\"\"\"\n",
    "\tcheck=[np.dot(Lbar,eigvec[:,i])-eigval[i]*eigvec[:,i] for i in range(0,k)]\n",
    "\tlength=[np.linalg.norm(e) for e in check]/np.spacing(1)\n",
    "\tprint(\"Lbar*v-lamda*v are %s*%s\" % (length,np.spacing(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDsL3QtFVE-q"
   },
   "outputs": [],
   "source": [
    "#setting of data generation\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector):\n",
    "    \n",
    "    transit_matrix=[]\n",
    "    for i in range(class_num):\n",
    "        transit_one=[epsilon_vector[i]]*i+[1-epsilon_vector[i]]+[epsilon_vector[i]]*(class_num-1-i)\n",
    "        transit_matrix+=[transit_one]\n",
    "    #print((number_of_nodes*link_inclass_prob*epsilon_vector[0])**0.5)\n",
    "    \n",
    "    adj=torch.zeros(number_of_nodes,Time_steps,number_of_nodes) #n*t*n adj matrix\n",
    "\n",
    "    #assign initial labels\n",
    "    labels=torch.randint(0,class_num,(number_of_nodes,)) #assign random label with equal probability\n",
    "    labels=labels.to(dtype=torch.long)\n",
    "    #label_node, speed up the generation of edges\n",
    "    label_node_dict=dict()\n",
    "\n",
    "    for j in range(class_num):\n",
    "            label_node_dict[j]=[]\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_node_dict[int(labels[i])]+=[int(i)]\n",
    "\n",
    "\n",
    "    #generate graph\n",
    "    for i in range(int(Time_steps)):\n",
    "        #change node\n",
    "        change_nodes=[]\n",
    "        for j in range(len(labels)):\n",
    "            if random.random()<epsilon_vector[labels[j]]:\n",
    "                #less than change probability\n",
    "                tmp=int(labels[j])\n",
    "                #print(j)\n",
    "                while(1): #change label\n",
    "                    labels[j]=torch.tensor(int(torch.randint(0,class_num,(1,))[0]))\n",
    "                    if labels[j]!=tmp:\n",
    "                        change_nodes+=[j]\n",
    "                        break\n",
    "                \n",
    "        label_node_dict=dict()\n",
    "        for j in range(class_num):\n",
    "            label_node_dict[j]=[]\n",
    "\n",
    "        for j in range(len(labels)):\n",
    "            label_node_dict[int(labels[j])]+=[int(j)]\n",
    "        #\n",
    "        #generate symmetrix adj matrix at each time step\n",
    "        for node_id in range(number_of_nodes):\n",
    "                j=labels[node_id]\n",
    "                for l in label_node_dict:\n",
    "                    if l==j:\n",
    "                        for z in label_node_dict[l]:  #z>node_id,  symmetrix matrix, no repeat\n",
    "                            if z>node_id and random.random()<link_inclass_prob:\n",
    "                                adj[node_id,i,z]= 1\n",
    "                                adj[z,i,node_id]= 1\n",
    "                    else:\n",
    "                        for z in label_node_dict[l]:\n",
    "                            if z>node_id and random.random()<link_outclass_prob:\n",
    "                                adj[node_id,i,z]= 1\n",
    "                                adj[z,i,node_id]= 1\n",
    "                              \n",
    "\n",
    "\n",
    "    #generate feature use eye matrix\n",
    "    features=torch.zeros(number_of_nodes,Time_steps,number_of_nodes)\n",
    "    for i in range(features.shape[1]):\n",
    "        features[:,i,:]=torch.eye(features.shape[0],features.shape[2])\n",
    "\n",
    "    #seprate train,val,test\n",
    "    idx_train = torch.LongTensor(range(number_of_nodes//5))\n",
    "    idx_val = torch.LongTensor(range(number_of_nodes//5, number_of_nodes//2))\n",
    "    idx_test = torch.LongTensor(range(number_of_nodes//2, number_of_nodes))\n",
    "\n",
    "    #probability matrix at last time_step\n",
    "    Probability_matrix=torch.zeros(number_of_nodes,number_of_nodes)\n",
    "    for j in range(number_of_nodes):\n",
    "        for k in range(number_of_nodes):\n",
    "          if j==k:\n",
    "                continue\n",
    "          elif labels[j]==labels[k]:\n",
    "            Probability_matrix[j][k]=link_inclass_prob\n",
    "          else:\n",
    "            Probability_matrix[j][k]=link_outclass_prob\n",
    "\n",
    "    return features.float(), adj.float(), labels, idx_train, idx_val, idx_test, Probability_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCrl5TV_eg5t"
   },
   "outputs": [],
   "source": [
    "def single_train_and_test(lambda_matrix, Probability_matrix, features, adj, labels, idx_train, idx_val, idx_test, model_type,normalize=False):\n",
    "\n",
    "    if model_type=='SPEC' or model_type=='SPEC_sklearn':\n",
    "          if type(lambda_matrix)!=type(None):\n",
    "              decay_adj=torch.zeros(adj.shape[0],adj.shape[2])\n",
    "              for j in range(adj.shape[0]):\n",
    "                  for k in range(adj.shape[2]):\n",
    "                      decay_adj[j][k]=lambda_matrix[labels[j]][labels[k]]\n",
    "              now_adj=adj[:,0,:].clone()\n",
    "              for i in range(1,adj.shape[1]):  #time_steps\n",
    "                          tmp_adj=adj[:,i,:].clone()\n",
    "                          \n",
    "                          now_adj=(1-decay_adj)*now_adj+decay_adj*tmp_adj\n",
    "            \n",
    "              adj=now_adj\n",
    "          else:\n",
    "              now_adj=adj[:,0,:].clone()\n",
    "              for i in range(1,adj.shape[1]):  #time_steps\n",
    "                      now_adj+=adj[:,i,:].clone()\n",
    "              adj=now_adj\n",
    "          if normalize==True:\n",
    "              #normalize in both cases\n",
    "              \n",
    "              adj+=torch.eye(adj.shape[0],adj.shape[1])\n",
    "              d=torch.sum(adj,axis=1)\n",
    "              D_minus_one_over_2=torch.zeros(adj.shape[0],adj.shape[0])\n",
    "              D_minus_one_over_2[range(len(D_minus_one_over_2)), range(len(D_minus_one_over_2))] = d**(-0.5)\n",
    "              adj=torch.mm(torch.mm(D_minus_one_over_2,adj),D_minus_one_over_2)\n",
    "\n",
    "          \n",
    "\n",
    "        \n",
    "\n",
    "          Lbar=np.array(adj)  #no normalizaton\n",
    "          top_k=class_num\n",
    "          kSigVal,kSigVec=getKlargestSigVec(Lbar,top_k)\n",
    "          centroid=kmeans(kSigVec.astype(float),class_num)[0] #change kSigvec from complex64 to float\n",
    "          result=vq(kSigVec.astype(float),centroid)[0]\n",
    "\n",
    "          \n",
    "          perm = permutations(range(class_num)) \n",
    "          one_hot_result=torch.tensor(one_hot(result,class_num))\n",
    "          acc_test=0\n",
    "          f1_test=0\n",
    "          auc_test=0\n",
    "          count=0\n",
    "          for i in perm: \n",
    "                count+=1\n",
    "                one_hot_i=one_hot(np.array(i))\n",
    "                perm_result=torch.mm(one_hot_result,torch.tensor(one_hot_i))\n",
    "                pred_labels=torch.argmax(perm_result,axis=1)\n",
    "                acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "                f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "                auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "                if count%10000==0:\n",
    "                  print(count)\n",
    "                  print(acc_test,f1_test,auc_test)   \n",
    "          print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "          try:\n",
    "              spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "          except:\n",
    "              spec_norm=[]\n",
    "          return 0,acc_test,spec_norm\n",
    "\n",
    "    elif model_type==\"DynAERNN\":\n",
    "        \n",
    "        length=adj.shape[1]\n",
    "        lookup=length-2\n",
    "\n",
    "        dim_emb  = class_num\n",
    "        if args_cuda:\n",
    "          tensorflow.device('/gpu:0')\n",
    "        embedding = DynAERNN(d   = dim_emb,\n",
    "            beta           = 5,\n",
    "            n_prev_graphs  = lookup,\n",
    "            nu1            = 1e-6,\n",
    "            nu2            = 1e-6,\n",
    "            n_aeunits      = [50, 30],\n",
    "            n_lstmunits    = [50,dim_emb],\n",
    "            rho            = 0.3,\n",
    "            n_iter         = args_epochs,\n",
    "            xeta           = 1e-3,\n",
    "            n_batch        = 10,\n",
    "            modelfile      = ['./intermediate/enc_model_dynAERNN.json', \n",
    "                              './intermediate/dec_model_dynAERNN.json'],\n",
    "            weightfile     = ['./intermediate/enc_weights_dynAERNN.hdf5', \n",
    "                              './intermediate/dec_weights_dynAERNN.hdf5'],\n",
    "            savefilesuffix = \"testing\")\n",
    "        embs = []\n",
    "        \n",
    "        graphs     = [nx.Graph(adj[:,l,:].numpy()) for l in range(length)]\n",
    "        for temp_var in range(lookup, length):\n",
    "                        emb, _ = embedding.learn_embeddings(graphs[:temp_var])\n",
    "                        embs.append(emb)\n",
    "        centroid=kmeans(embs[-1],class_num)[0] #change kSigvec from complex64 to float\n",
    "        result=vq(embs[-1],centroid)[0]\n",
    "\n",
    "        \n",
    "\n",
    "        perm = permutations(range(class_num)) \n",
    "        one_hot_result=torch.tensor(one_hot(result,class_num))\n",
    "        acc_test=0\n",
    "        f1_test=0\n",
    "        auc_test=0\n",
    "        count=0\n",
    "        for i in perm: \n",
    "              count+=1\n",
    "              one_hot_i=one_hot(np.array(i))\n",
    "              perm_result=torch.mm(one_hot_result,torch.tensor(one_hot_i))\n",
    "              pred_labels=torch.argmax(perm_result,axis=1)\n",
    "              acc_test = max(metrics.accuracy_score(labels,pred_labels),acc_test)\n",
    "              f1_test=max(metrics.f1_score(labels, pred_labels,average='weighted'),f1_test)\n",
    "              auc_test=max(metrics.roc_auc_score(one_hot(labels), perm_result,multi_class='ovr',average='weighted'),auc_test)\n",
    "              if count%10000==0:\n",
    "                print(count)\n",
    "                print(acc_test,f1_test,auc_test)   \n",
    "        print(str(acc_test)+'\\t'+str(f1_test)+'\\t'+str(auc_test))  \n",
    "        try:\n",
    "              spec_norm=getKlargestSigVec(adj-Probability_matrix,2)[0]\n",
    "        except:\n",
    "              spec_norm=[]\n",
    "        return 0,acc_test,spec_norm\n",
    "        \n",
    "\n",
    "\n",
    "    #choose adj matrix\n",
    "    #GCN:n*n, Others: n*t*n\n",
    "    if model_type=='GCN':  \n",
    "          if type(lambda_matrix)!=type(None):\n",
    "            decay_adj=torch.zeros(adj.shape[0],adj.shape[0])\n",
    "            for j in range(adj.shape[0]):\n",
    "                for k in range(adj.shape[2]):\n",
    "                    decay_adj[j][k]=lambda_matrix[labels[j]][labels[k]]\n",
    "            now_adj=adj[:,0,:].clone()\n",
    "            \n",
    "            for i in range(1,adj.shape[1]):  #time_steps\n",
    "                    tmp_adj=adj[:,i,:].clone()\n",
    "                    \n",
    "                    now_adj=(1-decay_adj)*now_adj+decay_adj*tmp_adj\n",
    "            adj=now_adj\n",
    "          else:\n",
    "              now_adj=adj[:,0,:].clone()\n",
    "              for i in range(1,adj.shape[1]):  #time_steps\n",
    "                      now_adj+=adj[:,i,:].clone()\n",
    "              adj=now_adj\n",
    "              \n",
    "          #normalize in both cases\n",
    "          if normalize==True:\n",
    "              adj+=torch.eye(adj.shape[0],adj.shape[1])\n",
    "              d=torch.sum(adj,axis=1)\n",
    "              D_minus_one_over_2=torch.zeros(adj.shape[0],adj.shape[0])\n",
    "              D_minus_one_over_2[range(len(D_minus_one_over_2)), range(len(D_minus_one_over_2))] = d**(-0.5)\n",
    "              adj=torch.mm(torch.mm(D_minus_one_over_2,adj),D_minus_one_over_2)\n",
    "              \n",
    "          \n",
    "          features=features[:,-1,:]\n",
    "          \n",
    "\n",
    "    elif model_type=='GAT' or model_type=='GraphSage':\n",
    "          now_adj=adj[:,0,:].clone()\n",
    "          for i in range(1,adj.shape[1]):  #time_steps\n",
    "                  now_adj+=adj[:,i,:].clone()\n",
    "          adj=now_adj\n",
    "          \n",
    "          #normalize in both cases\n",
    "          if normalize==True:\n",
    "              adj+=torch.eye(adj.shape[0],adj.shape[1])\n",
    "              d=torch.sum(adj,axis=1)\n",
    "              D_minus_one_over_2=torch.zeros(adj.shape[0],adj.shape[0])\n",
    "              D_minus_one_over_2[range(len(D_minus_one_over_2)), range(len(D_minus_one_over_2))] = d**(-0.5)\n",
    "              adj=torch.mm(torch.mm(D_minus_one_over_2,adj),D_minus_one_over_2)\n",
    "              \n",
    "          features=features[:,-1,:]\n",
    "    elif model_type=='EGCN':\n",
    "        adj=torch.transpose(adj,0,1)\n",
    "        features=torch.transpose(features,0,1)\n",
    "        \n",
    "\n",
    "    #define model\n",
    "    if model_type=='GCN':\n",
    "        model = GCN(nfeat=features.shape[1],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type=='RNNGCN':\n",
    "        model = RNNGCN(nfeat=features.shape[2],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type=='TRNNGCN':\n",
    "        model = TRNNGCN(nfeat=features.shape[2],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout,\n",
    "                nnode=features.shape[0],\n",
    "                use_cuda=args_cuda)\n",
    "    elif model_type=='GCNLSTM':\n",
    "        model = GCNLSTM(nfeat=features.shape[2],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type=='RGCN':\n",
    "        model = RGCN(nfeat=features.shape[2],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type==\"GAT\":\n",
    "        adj=dgl.from_networkx(nx.Graph(adj.numpy())) #fit in dgl\n",
    "        model = GAT(nfeat=features.shape[1],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type==\"GraphSage\":\n",
    "        adj=dgl.from_networkx(nx.Graph(adj.numpy())) #fit in dgl\n",
    "        model = GraphSage(nfeat=features.shape[1],\n",
    "                nhid=args_hidden,\n",
    "                nclass=class_num,\n",
    "                dropout=args_dropout)\n",
    "    elif model_type==\"EGCN\":\n",
    "        model = EGCN(nfeat=features.shape[2],\n",
    "                    nhid=args_hidden,\n",
    "                    nclass=class_num,\n",
    "                    device=torch.device('cpu'))\n",
    "\n",
    "    \n",
    "        \n",
    "    if model_type!=\"SPEC\" and model_type!=\"SPEC_sklearn\" and model_type!=\"DynAERNN\":\n",
    "        if args_cuda:\n",
    "            if model_type!='EGCN':\n",
    "                model=model.to(torch.device('cuda:0'))#.cuda()\n",
    "                features = features.cuda()\n",
    "                adj = adj.to(torch.device('cuda:0'))\n",
    "                labels = labels.cuda()\n",
    "                idx_train = idx_train.cuda()\n",
    "                idx_val = idx_val.cuda()\n",
    "                idx_test = idx_test.cuda()\n",
    "        #optimizer and train\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                              lr=args_lr, weight_decay=args_weight_decay)\n",
    "        # Train model\n",
    "        t_total = time.time()\n",
    "        best_val=0\n",
    "        for epoch in range(args_epochs):\n",
    "            acc_val=train(epoch, model, optimizer, features, adj, labels, idx_train, idx_val, model_type)\n",
    "            #print(model.Lambda)\n",
    "            if acc_val>best_val:\n",
    "              best_val=acc_val\n",
    "              loss, acc, auc, f1 = test(model, features, adj, labels, idx_test)\n",
    "              test_best_val=[loss,acc,auc,f1]\n",
    "            \n",
    "        # Testing\n",
    "        loss, acc, auc, f1 = test(model, features, adj, labels, idx_test)\n",
    "        if model_type=='RNNGCN' or model_type=='TRNNGCN':\n",
    "          print(model.Lambda,end='\\t')\n",
    "        #print(loss,acc)\n",
    "        print(str(test_best_val[1])+'\\t'+str(test_best_val[2])+'\\t'+str(test_best_val[3]))#,end='\\t')\n",
    "        try:\n",
    "            spec_norm=getKlargestSigVec(now_adj-Probability_matrix,2)[0]\n",
    "        except:\n",
    "            spec_norm=0 #temperal adj\n",
    "        return loss, acc, spec_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1F6reAUrAge"
   },
   "source": [
    "# Run Exp for Spectral Clustering and GCN with Decay Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA-ORtGokfVj"
   },
   "outputs": [],
   "source": [
    "def test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time):  \n",
    "     for times in range(sample_time):     \n",
    "          try:\n",
    "              features, adj, labels, idx_train, idx_val, idx_test, Probability_matrix=generate_data(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector)               \n",
    "              for i in np.arange(0.0, 1.01, 0.01):\n",
    "                        file_name='uncombined'+'_'+model_type+\"_\" +\"number_of_nodes_\"+str(number_of_nodes)+'_' +\"Time_steps_\"+str(Time_steps)+'_'\\\n",
    "                                      +\"class_num_\"+str(class_num)+'_' +\"link_inclass_prob_\"+str(link_inclass_prob)+'_'\\\n",
    "                                      +\"link_outclass_prob_\"+str(link_outclass_prob)+'_'+\"epsilon_vector_\"+str(epsilon_vector)+'_'\\\n",
    "                                      +\"sample_time_\"+str(sample_time)+\".txt\"\n",
    "                        if IN_COLAB==True:\n",
    "                            summary_file = open(\"/content/drive/My Drive/\"+file_name,\"a+\")\n",
    "                        else:\n",
    "                            summary_file = open(file_name,\"a+\")\n",
    "                        t=time.time()\n",
    "                        lambda_matrix=np.full((class_num,class_num),i)\n",
    "                        \n",
    "                        total_loss=0\n",
    "                        total_acc=0\n",
    "                        total_norm=[]\n",
    "                        loss, acc, specnorm = single_train_and_test(lambda_matrix,Probability_matrix,features, adj, labels, idx_train, idx_val, idx_test, model_type)\n",
    "\n",
    "                        summary_file.write(\"Weight decay: {}\".format(lambda_matrix.flatten()) +\n",
    "                                \"\\tTest set results:\" +\n",
    "                                \"\\tloss= {:.6f}\".format(loss) + \n",
    "                                \"\\taccuracy= {:.6f}\".format(acc)+\n",
    "                                \"\\tspecnorm= {}\\n\".format(specnorm))\n",
    "                        summary_file.close()\n",
    "          except:\n",
    "            error=1\n",
    "                \n",
    "def test_epsilon_vector_kxklambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time):  \n",
    "     for times in range(sample_time):     \n",
    "          try:\n",
    "              features, adj, labels, idx_train, idx_val, idx_test, Probability_matrix=generate_data(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector)               \n",
    "              for i in np.arange(0.0, 1.01, 0.1):\n",
    "                for j in np.arange(0, 1.01, 0.1):\n",
    "                  for k in np.arange(0, 1.01, 0.1):\n",
    "                    for l in np.arange(0, 1.01, 0.1):\n",
    "                        file_name='uncombined'+'_'+'kxklambda'+'_'+model_type+\"_\" +\"number_of_nodes_\"+str(number_of_nodes)+'_' +\"Time_steps_\"+str(Time_steps)+'_'\\\n",
    "                                      +\"class_num_\"+str(class_num)+'_' +\"link_inclass_prob_\"+str(link_inclass_prob)+'_'\\\n",
    "                                      +\"link_outclass_prob_\"+str(link_outclass_prob)+'_'+\"epsilon_vector_\"+str(epsilon_vector)+'_'\\\n",
    "                                      +\"sample_time_\"+str(sample_time)+\".txt\"\n",
    "                        if IN_COLAB==True:\n",
    "                            summary_file = open(\"/content/drive/My Drive/\"+file_name,\"a+\")\n",
    "                        else:\n",
    "                            summary_file = open(file_name,\"a+\")\n",
    "                        t=time.time()\n",
    "                        lambda_matrix=np.array([[i,j],[k,l]])\n",
    "                        total_loss=0\n",
    "                        total_acc=0\n",
    "                        total_norm=[]\n",
    "                        loss, acc, specnorm = single_train_and_test(lambda_matrix,Probability_matrix,features, adj, labels, idx_train, idx_val, idx_test, model_type)\n",
    "\n",
    "                        summary_file.write(\"Weight decay: {}\".format(lambda_matrix.flatten()) +\n",
    "                                \"\\tTest set results:\" +\n",
    "                                \"\\tloss= {:.6f}\".format(loss) + \n",
    "                                \"\\taccuracy= {:.6f}\".format(acc)+\n",
    "                                \"\\tspecnorm= {}\\n\".format(specnorm))\n",
    "                        \n",
    "                        summary_file.close()\n",
    "          except:\n",
    "            error=1\n",
    "            \n",
    "def test_kxk_neural_network(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time):  \n",
    "     for times in range(sample_time):     \n",
    "              features, adj, labels, idx_train, idx_val, idx_test, Probability_matrix=generate_data(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector)               \n",
    "              for i in range(1):\n",
    "                        file_name='uncombined'+'_'+'kxklambda'+'_'+model_type+\"_\" +\"number_of_nodes_\"+str(number_of_nodes)+'_' +\"Time_steps_\"+str(Time_steps)+'_'\\\n",
    "                                      +\"class_num_\"+str(class_num)+'_' +\"link_inclass_prob_\"+str(link_inclass_prob)+'_'\\\n",
    "                                      +\"link_outclass_prob_\"+str(link_outclass_prob)+'_'+\"epsilon_vector_\"+str(epsilon_vector)+'_'\\\n",
    "                                      +\"sample_time_\"+str(sample_time)+\".txt\"\n",
    "                        if IN_COLAB==True:\n",
    "                            summary_file = open(\"/content/drive/My Drive/\"+file_name,\"a+\")\n",
    "                        else:\n",
    "                            summary_file = open(file_name,\"a+\")\n",
    "                        t=time.time()\n",
    "                        lambda_matrix=np.full((class_num,class_num),0.2)\n",
    "                        #print(\"current matrix: {}\".format(lambda_matrix))\n",
    "                        total_loss=0\n",
    "                        total_acc=0\n",
    "                        total_norm=[]\n",
    "                        loss, acc, specnorm = single_train_and_test(lambda_matrix,Probability_matrix,features, adj, labels, idx_train, idx_val, idx_test, model_type)\n",
    "                        \n",
    "                        summary_file.write(\"Weight decay: {}\".format(lambda_matrix.flatten()) +\n",
    "                                \"\\tTest set results:\" +\n",
    "                                \"\\tloss= {:.6f}\".format(loss) + \n",
    "                                \"\\taccuracy= {:.6f}\".format(acc)+\n",
    "                                \"\\tspecnorm= {}\\n\".format(specnorm))\n",
    "                        print(i,loss,acc,specnorm)\n",
    "                        #print(time.time()-t)\n",
    "                        summary_file.close()\n",
    "\n",
    "\n",
    "                        \n",
    "#For simulated graphs\n",
    "\n",
    "sample_time=100\n",
    "number_of_nodes=200\n",
    "Time_steps=500\n",
    "class_num=2\n",
    "link_inclass_prob=20/number_of_nodes/5  #when calculation , remove the link in itself\n",
    "\n",
    "link_outclass_prob=link_inclass_prob/20\n",
    "epsilon_vector=[10/number_of_nodes,20/number_of_nodes]\n",
    "\n",
    "\n",
    "\n",
    "model_type='SPEC'    #GCN, GAT, GraphSage #SPEC(DynSPEC), DynAERNN #GCNLSTM, EGCN, RNNGCN, TRNNGCN\n",
    "args_hidden = class_num\n",
    "args_dropout = 0.5\n",
    "args_lr = 0.01\n",
    "args_weight_decay = 5e-4\n",
    "args_epochs = 250\n",
    "args_no_cuda=False\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###Different setting on simulated graphs\n",
    "\n",
    "#test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "\n",
    "\n",
    "#for number_of_nodes in [100,250,500]:\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for link_inclass_prob in [10/number_of_nodes/5,20/number_of_nodes/5,30/number_of_nodes/5]:\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for epsilon_vector in [[10/number_of_nodes,10/number_of_nodes],[20/number_of_nodes,20/number_of_nodes],[30/number_of_nodes,30/number_of_nodes],[40/number_of_nodes,40/number_of_nodes],[50/number_of_nodes,50/number_of_nodes],[60/number_of_nodes,60/number_of_nodes]]:\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for Time_steps in [1000,2000,5000,10000]: #already have 500\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for sample_time in [1,10,1000]: #already have 100\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for epsilon_vector in [[10/number_of_nodes,20/number_of_nodes],[10/number_of_nodes,30/number_of_nodes],[20/number_of_nodes,30/number_of_nodes]]:\n",
    "#    test_epsilon_vector_onelambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "#for epsilon_vector in [[10/number_of_nodes,20/number_of_nodes],[10/number_of_nodes,30/number_of_nodes],[20/number_of_nodes,30/number_of_nodes]]:\n",
    "#for epsilon_vector in [[10/number_of_nodes,40/number_of_nodes],[20/number_of_nodes,40/number_of_nodes],[30/number_of_nodes,40/number_of_nodes]]:\n",
    "#    test_epsilon_vector_kxklambda(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n",
    "\n",
    "\n",
    "#test_kxk_neural_network(model_type,number_of_nodes,Time_steps,class_num,link_inclass_prob,link_outclass_prob, epsilon_vector,sample_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Exp on Simulated and Real Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i7evijEI2Vu"
   },
   "outputs": [],
   "source": [
    "def load_real_data(dataset_name):\n",
    "    dataset_dict=dict()\n",
    "    dataset_dict[\"DBLP3\"]=\"DBLP3.npz\"\n",
    "    dataset_dict[\"DBLP5\"]=\"DBLP5.npz\"\n",
    "    dataset_dict[\"Brain\"]=\"Brain.npz\"\n",
    "    dataset_dict[\"Reddit\"]=\"reddit.npz\"\n",
    "    dataset_dict[\"DBLPE\"]=\"DBLPE.npz\"\n",
    "    \n",
    "    dataset      = np.load(dataset_dict[dataset_name])\n",
    "    \n",
    "    \n",
    "    Graphs    = torch.LongTensor(dataset['adjs'])    #(n_time, n_node, n_node)\n",
    "    Graphs=torch.transpose(Graphs,0,1) #(n_node, n_time, n_node)\n",
    "\n",
    "    now_adj=Graphs[:,0,:].clone()\n",
    "    for i in range(1,Graphs.shape[1]):  #time_steps\n",
    "                  now_adj+=Graphs[:,i,:].clone()\n",
    "    d=torch.sum(now_adj,axis=1)\n",
    "    non_zero_index=torch.nonzero(d,as_tuple=True)[0]\n",
    "    Graphs=Graphs[non_zero_index,:,:]\n",
    "    Graphs=Graphs[:,:,non_zero_index]\n",
    "    \n",
    "\n",
    "    if dataset_name==\"DBLPE\":\n",
    "      Labels = torch.LongTensor(np.argmax(dataset['labels'],axis=2))  #(n_node, n_time, num_classes) argmax\n",
    "      Features=torch.zeros(Graphs.shape)\n",
    "      for i in range(Features.shape[1]):\n",
    "          Features[:,i,:]=torch.eye(Features.shape[0],Features.shape[2])\n",
    "      Labels=Labels[non_zero_index]\n",
    "      \n",
    "    else:\n",
    "      Labels    = torch.LongTensor(np.argmax(dataset['labels'],axis=1))  #(n_node, num_classes) argmax\n",
    "      Features  = torch.LongTensor(dataset['attmats']) #(n_node, n_time, att_dim)\n",
    "  \n",
    "      Features=Features[non_zero_index]\n",
    "      Labels=Labels[non_zero_index]\n",
    "    \n",
    "\n",
    "    \n",
    "    #shuffle datasets\n",
    "    number_of_nodes=Graphs.shape[0]\n",
    "    nodes_id=list(range(number_of_nodes))\n",
    "    random.shuffle(nodes_id)\n",
    "    idx_train = torch.LongTensor(nodes_id[:(7*number_of_nodes)//10])\n",
    "    idx_val = torch.LongTensor(nodes_id[(7*number_of_nodes)//10: (9*number_of_nodes)//10])\n",
    "    idx_test = torch.LongTensor(nodes_id[(9*number_of_nodes)//10: number_of_nodes])\n",
    "    \n",
    "    return Features.float(), Graphs.float(), Labels.long(), idx_train, idx_val, idx_test, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQGUXDVCRvh4"
   },
   "outputs": [],
   "source": [
    "def test_real_dataset():\n",
    "                  \n",
    "    file_name=dataset_name+'_'+model_type+\".txt\"\n",
    "    if IN_COLAB==True:\n",
    "        summary_file = open(\"/content/drive/My Drive/\"+file_name,\"a+\")\n",
    "    else:\n",
    "        summary_file = open(file_name,\"a+\")\n",
    "    t=time.time()\n",
    "    lambda_matrix=None \n",
    "    total_loss=0\n",
    "    total_acc=0\n",
    "    total_norm=[]\n",
    "    loss, acc, specnorm = single_train_and_test(lambda_matrix,Probability_matrix,features, adj, labels, idx_train, idx_val, idx_test, model_type,normalize=args_normalize)\n",
    "    if type(lambda_matrix)!=type(None):\n",
    "        summary_file.write(\"Weight decay: {}\".format(lambda_matrix.flatten()) +\n",
    "                                    \"\\tTest set results:\" +\n",
    "                                    \"\\tloss= {:.6f}\".format(loss) + \n",
    "                                    \"\\taccuracy= {:.6f}\".format(acc)+\n",
    "                                    \"\\tspecnorm= {}\\n\".format(specnorm))\n",
    "    else:\n",
    "        summary_file.write(\"Weight decay: {}\".format(0) +\n",
    "                                    \"\\tTest set results:\" +\n",
    "                                    \"\\tloss= {:.6f}\".format(loss) + \n",
    "                                    \"\\taccuracy= {:.6f}\".format(acc)+\n",
    "                                    \"\\tspecnorm= {}\\n\".format(specnorm))\n",
    "    \n",
    "    summary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMHZprmsOTdl"
   },
   "outputs": [],
   "source": [
    "#simulated data: setting of data generation\n",
    "\n",
    "def generate_data_totallabel(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector):\n",
    "    \n",
    "    transit_matrix=[]\n",
    "    for i in range(class_num):\n",
    "        transit_one=[epsilon_vector[i]]*i+[1-epsilon_vector[i]]+[epsilon_vector[i]]*(class_num-1-i)\n",
    "        transit_matrix+=[transit_one]\n",
    "    #print((number_of_nodes*link_inclass_prob*epsilon_vector[0])**0.5)\n",
    "    \n",
    "    adj=torch.zeros(number_of_nodes,Time_steps,number_of_nodes) #n*t*n adj matrix\n",
    "\n",
    "    #assign initial labels\n",
    "    labels=torch.randint(0,class_num,(number_of_nodes,)) #assign random label with equal probability\n",
    "    labels=labels.to(dtype=torch.long)\n",
    "    #label_node, speed up the generation of edges\n",
    "    label_node_dict=dict()\n",
    "\n",
    "    for j in range(class_num):\n",
    "            label_node_dict[j]=[]\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label_node_dict[int(labels[i])]+=[int(i)]\n",
    "\n",
    "    total_labels=torch.zeros(number_of_nodes,Time_steps)\n",
    "    #generate graph\n",
    "    for i in range(int(Time_steps)):\n",
    "        #change node\n",
    "        change_nodes=[]\n",
    "        for j in range(len(labels)):\n",
    "            if random.random()<epsilon_vector[labels[j]]:\n",
    "                #less than change probability\n",
    "                tmp=int(labels[j])\n",
    "                #print(j)\n",
    "                while(1): #change label\n",
    "                    labels[j]=torch.tensor(int(torch.randint(0,class_num,(1,))[0]))\n",
    "                    if labels[j]!=tmp:\n",
    "                        change_nodes+=[j]\n",
    "                        break\n",
    "                #labels[j]=torch.tensor(not tmp)\n",
    "        total_labels[:,i]=labels.clone()\n",
    "        label_node_dict=dict()\n",
    "        for j in range(class_num):\n",
    "            label_node_dict[j]=[]\n",
    "\n",
    "        for j in range(len(labels)):\n",
    "            label_node_dict[int(labels[j])]+=[int(j)]\n",
    "        #\n",
    "        #generate symmetrix adj matrix at each time step\n",
    "        for node_id in range(number_of_nodes):\n",
    "                j=labels[node_id]\n",
    "                for l in label_node_dict:\n",
    "                    if l==j:\n",
    "                        for z in label_node_dict[l]:  #z>node_id,  symmetrix matrix, no repeat\n",
    "                            if z>node_id and random.random()<link_inclass_prob:\n",
    "                                adj[node_id,i,z]= 1\n",
    "                                adj[z,i,node_id]= 1\n",
    "                    else:\n",
    "                        for z in label_node_dict[l]:\n",
    "                            if z>node_id and random.random()<link_outclass_prob:\n",
    "                                adj[node_id,i,z]= 1\n",
    "                                adj[z,i,node_id]= 1\n",
    "                              \n",
    "\n",
    "\n",
    "    #generate feature use eye matrix\n",
    "    features=torch.zeros(number_of_nodes,Time_steps,number_of_nodes)\n",
    "    for i in range(features.shape[1]):\n",
    "        features[:,i,:]=torch.eye(features.shape[0],features.shape[2])\n",
    "\n",
    "    #seprate train,val,test\n",
    "    idx_train = torch.LongTensor(range(number_of_nodes//5))\n",
    "    idx_val = torch.LongTensor(range(number_of_nodes//5, number_of_nodes//2))\n",
    "    idx_test = torch.LongTensor(range(number_of_nodes//2, number_of_nodes))\n",
    "\n",
    "    #probability matrix at last time_step\n",
    "    Probability_matrix=torch.zeros(number_of_nodes,number_of_nodes)\n",
    "    for j in range(number_of_nodes):\n",
    "        for k in range(number_of_nodes):\n",
    "          if j==k:\n",
    "                continue\n",
    "          elif labels[j]==labels[k]:\n",
    "            Probability_matrix[j][k]=link_inclass_prob\n",
    "          else:\n",
    "            Probability_matrix[j][k]=link_outclass_prob\n",
    "\n",
    "    return features.float(), adj.float(), total_labels.long(), idx_train, idx_val, idx_test, Probability_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33976,
     "status": "ok",
     "timestamp": 1598996397893,
     "user_tz": 240
    },
    "id": "ubM8c3SqXwA3",
    "outputId": "ec951aa1-29eb-4347-8e14-c539af22a1d4"
   },
   "outputs": [],
   "source": [
    "mode=\"real\"\n",
    "\n",
    "if mode=='real':\n",
    "    dataset_name=\"DBLPE\"\n",
    "    features, adj, labels, idx_train, idx_val, idx_test, Probability_matrix=load_real_data(dataset_name) \n",
    "\n",
    "    class_num=int(labels.max())+1\n",
    "    print(class_num)\n",
    "    total_adj=adj\n",
    "    total_labels=labels\n",
    "elif mode=='simulate':\n",
    "    dataset_name=''\n",
    "    number_of_nodes=200\n",
    "    Time_steps=50\n",
    "    class_num=2\n",
    "    link_inclass_prob=20/number_of_nodes/5  #when calculation , remove the link in itself\n",
    "    #EGCN good when network is dense 20/number_of_nodes  #fails when network is sparse. 20/number_of_nodes/5\n",
    "\n",
    "    link_outclass_prob=link_inclass_prob/20\n",
    "    epsilon_vector=[10/number_of_nodes,20/number_of_nodes]\n",
    "\n",
    "\n",
    "    features, adj, labels, idx_train, idx_val, idx_test, Probability_matrix=generate_data_totallabel(number_of_nodes, Time_steps, class_num, link_inclass_prob, link_outclass_prob, epsilon_vector)               \n",
    "    total_adj=adj\n",
    "    total_labels=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3jDXPAhGUu16",
    "outputId": "3ca64158-7574-4b43-9fc3-63718e9a8977"
   },
   "outputs": [],
   "source": [
    "model_type='TRNNGCN'    #GCN, GAT, GraphSage #dynamic_spec, DynAERNN #GCNLSTM, EGCN, RNNGCN, TRNNGCN\n",
    "args_hidden = class_num\n",
    "args_dropout = 0.5\n",
    "args_lr = 0.0025\n",
    "args_weight_decay = 5e-4\n",
    "args_epochs = 500 \n",
    "args_no_cuda=True\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "args_normalize=True\n",
    "\n",
    "if mode=='real':\n",
    "    if dataset_name==\"DBLPE\":\n",
    "      #target_time=13 #0-13\n",
    "      for target_time in range(0,14):\n",
    "          print(target_time,end='\\t')\n",
    "          adj = total_adj[:,:target_time+1,:]\n",
    "          labels = total_labels[:,target_time]\n",
    "          test_real_dataset()\n",
    "          print(' ',end='\\n')\n",
    "    else:\n",
    "        test_real_dataset()\n",
    "elif mode=='simulate':\n",
    "    for target_time in range(0,total_labels.shape[1]):\n",
    "          print(target_time,end='\\t')\n",
    "          adj = total_adj[:,:target_time+1,:]\n",
    "          labels = total_labels[:,target_time]\n",
    "          test_real_dataset()\n",
    "          print(' ',end='\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GCN_paprmeters.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
